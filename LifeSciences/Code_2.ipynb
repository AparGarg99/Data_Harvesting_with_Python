{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import glob\n",
    "import pandas as pd\n",
    "import time\n",
    "import shutil, os\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import date\n",
    "################ WEB SCRAPING MODULES ############\n",
    "import bs4\n",
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today() \n",
    "try:\n",
    "    os.mkdir(str(today))\n",
    "    os.mkdir(str(today)+'/Patent files')\n",
    "    os.mkdir(str(today)+'/Trials files')\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of non-public companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\aparg\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to enter companies one by one?(y/n): n\n",
      "enter name of excel file: non-public.xlsx\n",
      "enter column containing list of companies: Company\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MolecuLight Inc.',\n",
       " 'PicnicHealth',\n",
       " 'Syapse',\n",
       " 'Sapience Therapeutics',\n",
       " 'Surgical Theater',\n",
       " 'Onlume Surgical',\n",
       " 'KAHR Medical',\n",
       " 'CorWave SA',\n",
       " 'Goldfinch Bio']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install()) # open Chrome driver/window\n",
    "user=input('Do you want to enter companies one by one?(y/n): ')\n",
    "l=[]\n",
    "if(user=='y'):\n",
    "    more='y'\n",
    "    while(more=='y'):\n",
    "        a=input('enter company name: ')\n",
    "        l.append(a)\n",
    "        more=input('do you want to enter more companies(y/n): ')\n",
    "else:\n",
    "    csv=input('enter name of excel file: ') # put non-public.xlsx\n",
    "    companies=input('enter column containing list of companies: ') # put Company\n",
    "    try:\n",
    "        l=list(pd.read_csv(csv)[companies])\n",
    "    except:\n",
    "        l=list(pd.read_excel(csv,engine='openpyxl')[companies])\n",
    "l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape [Google Patents](https://patents.google.com/) for Patents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sheet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete old csv files in directories (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete(directory):\n",
    "    filelist = [ f for f in os.listdir(directory) if f.endswith(\".csv\")]\n",
    "    for f in filelist:\n",
    "        os.remove(os.path.join(directory, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from \"Downloads\" directory\n",
    "delete('C:/Users/aparg/Downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from directory created\n",
    "directory='C:/Users/aparg/Desktop/LifeSciences/'+str(today)\n",
    "delete(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from subdirectory\n",
    "delete(directory+'/Patent files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape patents for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MolecuLight Inc.\n",
      "1 PicnicHealth\n",
      "2 Syapse\n",
      "3 Sapience Therapeutics\n",
      "4 Surgical Theater\n",
      "5 Onlume Surgical\n",
      "6 KAHR Medical\n",
      "7 CorWave SA\n",
      "8 Goldfinch Bio\n"
     ]
    }
   ],
   "source": [
    "for j,i in enumerate(l):\n",
    "    try:\n",
    "        print(j,i)\n",
    "        link=\"https://patents.google.com/xhr/query?url=assignee%3D{}%26oq%3D{}&exp=&download=true\".format(\"%2B\".join(i.split()),\"%2B\".join(i.split()))\n",
    "        # download csv\n",
    "        webbrowser.open(link)\n",
    "        # wait for 20 sec\n",
    "        time.sleep(20)\n",
    "        # read csv from downloads\n",
    "        all_files = glob.glob(os.path.join(r'C:\\Users\\aparg\\Downloads', \"*.csv\"))\n",
    "        # rename csv\n",
    "        os.rename(all_files[0],'C:/Users/aparg/Downloads/'+i+'.csv')\n",
    "        # copy csv to req. folder\n",
    "        shutil.copy('C:/Users/aparg/Downloads/'+i+'.csv', directory+'/Patent files')\n",
    "        # delete csv from downloads\n",
    "        delete('C:/Users/aparg/Downloads')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all patent files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files in subdirectory \"Patent files\"\n",
    "all_files = glob.glob(os.path.join(directory+'/Patent files', \"*.csv\"))  \n",
    "# concatenate all csv files present in \"Patent files\"\n",
    "df_from_each_file = (pd.read_csv(f,header=1) for f in all_files)\n",
    "concatenated_df = pd.concat(df_from_each_file, ignore_index=True)\n",
    "concatenated_df=concatenated_df[['id','title','publication date','assignee','inventor/author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering output based on \"assignee\"\n",
    "appended_data = []\n",
    "for company in l:\n",
    "    s = pd.Series([str(i).lower() for i in concatenated_df['assignee']])\n",
    "    k=s[s.str.contains(company.lower())].index\n",
    "    if(list(k)!=[]):\n",
    "        data = concatenated_df.loc[k]\n",
    "        data['assignee']=[company for i in range(data.shape[0])]\n",
    "        appended_data.append(data)\n",
    "appended_data = pd.concat(appended_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \"Year Filed\" from \"publication date\"\n",
    "appended_data['Year Filed']=appended_data['publication date'].apply(lambda x:str(x).split('-')[0])\n",
    "# selecting required columns\n",
    "appended_data=appended_data[['assignee','id', 'title', 'publication date','Year Filed','inventor/author']]\n",
    "# renaming columns\n",
    "appended_data.columns=['Company Name/Assignee','Patent No.','Title','Publication Date','Year Filed','Inventors/Authors']\n",
    "appended_data['Year Filed']=appended_data['Year Filed'].replace('nan',np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name/Assignee</th>\n",
       "      <th>Patent No.</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publication Date</th>\n",
       "      <th>Year Filed</th>\n",
       "      <th>Inventors/Authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MolecuLight Inc.</td>\n",
       "      <td>AU-2019264864-A1</td>\n",
       "      <td>Imaging drapes, packaging for drapes, methods ...</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>2021</td>\n",
       "      <td>Ralph DACOSTA, Danielle DUNHAM, Sonia GULIA, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>MolecuLight Inc.</td>\n",
       "      <td>US-D903863-S</td>\n",
       "      <td>Adapter for supporting a darkening drape</td>\n",
       "      <td>2020-12-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ralph S. DaCosta, Simon Treadwell, Sonia Gulia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MolecuLight Inc.</td>\n",
       "      <td>US-2020364862-A1</td>\n",
       "      <td>Wound imaging and analysis</td>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ralph DACOSTA, Todd E. MEANEY, Todd Daynes, Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>MolecuLight Inc.</td>\n",
       "      <td>WO-2020148726-A1</td>\n",
       "      <td>Système modulaire d'imagerie et d'analyse mult...</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020</td>\n",
       "      <td>Ralph DACOSTA, Simon Treadwell, Connor WRIGHT,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Sapience Therapeutics</td>\n",
       "      <td>US-10316077-B2</td>\n",
       "      <td>Cell-penetrating ATF5 polypeptides and uses th...</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>2019</td>\n",
       "      <td>Barry Jay Kappel, Jimmy Andrew Rotolo, Gene Me...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company Name/Assignee        Patent No.  \\\n",
       "30       MolecuLight Inc.  AU-2019264864-A1   \n",
       "35       MolecuLight Inc.      US-D903863-S   \n",
       "36       MolecuLight Inc.  US-2020364862-A1   \n",
       "39       MolecuLight Inc.  WO-2020148726-A1   \n",
       "40  Sapience Therapeutics    US-10316077-B2   \n",
       "\n",
       "                                                Title Publication Date  \\\n",
       "30  Imaging drapes, packaging for drapes, methods ...       2021-01-07   \n",
       "35          Adapter for supporting a darkening drape        2020-12-01   \n",
       "36                        Wound imaging and analysis        2020-11-19   \n",
       "39  Système modulaire d'imagerie et d'analyse mult...       2020-07-23   \n",
       "40  Cell-penetrating ATF5 polypeptides and uses th...       2019-06-11   \n",
       "\n",
       "   Year Filed                                  Inventors/Authors  \n",
       "30       2021  Ralph DACOSTA, Danielle DUNHAM, Sonia GULIA, N...  \n",
       "35       2020  Ralph S. DaCosta, Simon Treadwell, Sonia Gulia...  \n",
       "36       2020  Ralph DACOSTA, Todd E. MEANEY, Todd Daynes, Ga...  \n",
       "39       2020  Ralph DACOSTA, Simon Treadwell, Connor WRIGHT,...  \n",
       "40       2019  Barry Jay Kappel, Jimmy Andrew Rotolo, Gene Me...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Scraped Patents using [USPTO](http://patft.uspto.gov/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\aparg\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.101\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install()) # open Chrome driver/window\n",
    "links=[]\n",
    "for i in l:\n",
    "    term=\"+\".join(i.split())\n",
    "    driver.get('http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r=0&f=S&l=50&TERM1={}&FIELD1=ASNM&co1=AND&TERM2=&FIELD2=&d=PTXT'.format(term))\n",
    "    source = driver.page_source\n",
    "    soup=bs4.BeautifulSoup(source, 'html.parser')\n",
    "    #################### GET LINKS OF PAGES FOR EACH COMPANY #####################\n",
    "    try:\n",
    "        no_of_pages=int(soup.find_all('strong')[len(soup.find_all('strong'))-1].text)\n",
    "        for page in range(no_of_pages):\n",
    "            link='http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&r={}&f=G&l=50&co1=AND&d=PTXT&s1=%22{}%22.ASNM.&OS=AN/%22{}al%22&RS=AN/%22{}%22'.format(page+1,term,term,term)\n",
    "            links.append(link)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "for j in links:\n",
    "    driver.get(j)\n",
    "    source = driver.page_source\n",
    "    soup=bs4.BeautifulSoup(source, 'html.parser')\n",
    "    try:\n",
    "        text=soup.find('font',{'size':'+1'}).text.strip()\n",
    "        title.append(text)\n",
    "    except:\n",
    "        pass\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data['Title']=appended_data['Title'].apply(lambda x:x.strip())\n",
    "appended_data=appended_data.loc[appended_data['Title'].isin(list(set(title)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data=appended_data.drop_duplicates(subset=['Company Name/Assignee', 'Title'])\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape [Clinical Trials](https://clinicaltrials.gov/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape trials for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MolecuLight Inc.\n",
      "1 PicnicHealth\n",
      "2 Syapse\n",
      "3 Sapience Therapeutics\n",
      "4 Surgical Theater\n",
      "5 Onlume Surgical\n",
      "6 KAHR Medical\n",
      "7 CorWave SA\n",
      "8 Goldfinch Bio\n"
     ]
    }
   ],
   "source": [
    "for j,i in enumerate(l):\n",
    "    try:\n",
    "        print(j,i)\n",
    "        link=\"https://clinicaltrials.gov/ct2/results/download_fields?cond=&term={}&type=&down_fmt=csv&down_flds=all&rslt=&age_v=&gndr=&intr=&titles=&outc=&spons=&lead=&id=&cntry=&state=&city=&dist=&locn=&fund=2&rsub=&strd_s=&strd_e=&prcd_s=&prcd_e=&sfpd_s=&sfpd_e=&rfpd_s=&rfpd_e=&lupd_s=&lupd_e=&sort=\".format(\"+\".join(i.split()))\n",
    "        df = pd.read_csv(link)\n",
    "        df=df[['First Posted','NCT Number','Title','Start Date','Completion Date','Sponsor/Collaborators']]\n",
    "        df['Company Name']=[i for j in range(df.shape[0])]\n",
    "        df.to_csv(directory+'/Trials files/'+i+'.csv',index=False)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all trials files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(directory+'/Trials files', \"*.csv\"))  \n",
    "if(all_files!=[]):\n",
    "    a=pd.read_csv(all_files[0])\n",
    "    for i in all_files[1:]:\n",
    "        a=pd.concat([a,pd.read_csv(i)])\n",
    "        \n",
    "    a['Principal Investigator']=['-' for j in range(a.shape[0])]\n",
    "    a=a[['Company Name','NCT Number','Title', 'Start Date', 'Completion Date','Sponsor/Collaborators','Principal Investigator']] \n",
    "    a.columns=['Company Name','Clinical Trial Identifier','Title of study',\n",
    "               'Start Date','End Date','Sponsor Company','Principal Investigator']\n",
    "    a['C'] = a.apply(lambda x: str(x['Company Name']) in str(x['Sponsor Company']), axis=1)\n",
    "    a=a.loc[a['C']==True]\n",
    "    a=a.drop('C',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error occurred during loading data. Trying to use cache server https://fake-useragent.herokuapp.com/browsers/0.1.11\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\aparg\\anaconda3\\envs\\divya\\lib\\site-packages\\fake_useragent\\utils.py\", line 154, in load\n",
      "    for item in get_browsers(verify_ssl=verify_ssl):\n",
      "  File \"c:\\users\\aparg\\anaconda3\\envs\\divya\\lib\\site-packages\\fake_useragent\\utils.py\", line 99, in get_browsers\n",
      "    html = html.split('<table class=\"w3-table-all notranslate\">')[1]\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "if(all_files!=[]):\n",
    "    ua = UserAgent()\n",
    "    for i in range(a.shape[0]):\n",
    "        url='https://clinicaltrials.gov/ct2/show/{}'.format(a.iloc[i,1])\n",
    "        response = requests.get(url, {\"User-Agent\": ua.random})\n",
    "        if response.status_code == 200:\n",
    "            soup = bs4.BeautifulSoup(response.text, \"html.parser\")\n",
    "            for j in soup.find_all('table',{'class':'ct-layout_table tr-indent2'}):\n",
    "                m=j.text\n",
    "                if('Study Director:' in m):\n",
    "                    a.iloc[i,-1]=m[m.index('Study Director:')+16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Clinical Trial Identifier</th>\n",
       "      <th>Title of study</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>End Date</th>\n",
       "      <th>Sponsor Company</th>\n",
       "      <th>Principal Investigator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldfinch Bio</td>\n",
       "      <td>NCT04880291</td>\n",
       "      <td>First-In-Human Study of GFB-024 in Healthy Ove...</td>\n",
       "      <td>May 5, 2021</td>\n",
       "      <td>November 6, 2021</td>\n",
       "      <td>Goldfinch Bio, Inc.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goldfinch Bio</td>\n",
       "      <td>NCT04387448</td>\n",
       "      <td>A Study of TRPC5 Channel Inhibitor in Patients...</td>\n",
       "      <td>July 28, 2020</td>\n",
       "      <td>December 2021</td>\n",
       "      <td>Goldfinch Bio, Inc.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldfinch Bio</td>\n",
       "      <td>NCT04235621</td>\n",
       "      <td>A Study to Understand the Genetics and Clinica...</td>\n",
       "      <td>December 20, 2019</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>Goldfinch Bio, Inc.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goldfinch Bio</td>\n",
       "      <td>NCT03970122</td>\n",
       "      <td>FIH Ph 1 Study of TRPC5 Channel Inhibitor GFB-...</td>\n",
       "      <td>May 29, 2019</td>\n",
       "      <td>April 4, 2020</td>\n",
       "      <td>Goldfinch Bio, Inc.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MolecuLight Inc.</td>\n",
       "      <td>NCT03540004</td>\n",
       "      <td>Evaluation of MolecuLight i:X as an Adjunctive...</td>\n",
       "      <td>May 23, 2018</td>\n",
       "      <td>December 30, 2020</td>\n",
       "      <td>MolecuLight Inc.|SerenaGroup, Inc.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company Name Clinical Trial Identifier  \\\n",
       "0     Goldfinch Bio               NCT04880291   \n",
       "1     Goldfinch Bio               NCT04387448   \n",
       "2     Goldfinch Bio               NCT04235621   \n",
       "3     Goldfinch Bio               NCT03970122   \n",
       "4  MolecuLight Inc.               NCT03540004   \n",
       "\n",
       "                                      Title of study         Start Date  \\\n",
       "0  First-In-Human Study of GFB-024 in Healthy Ove...        May 5, 2021   \n",
       "1  A Study of TRPC5 Channel Inhibitor in Patients...      July 28, 2020   \n",
       "2  A Study to Understand the Genetics and Clinica...  December 20, 2019   \n",
       "3  FIH Ph 1 Study of TRPC5 Channel Inhibitor GFB-...       May 29, 2019   \n",
       "4  Evaluation of MolecuLight i:X as an Adjunctive...       May 23, 2018   \n",
       "\n",
       "            End Date                     Sponsor Company  \\\n",
       "0   November 6, 2021                 Goldfinch Bio, Inc.   \n",
       "1      December 2021                 Goldfinch Bio, Inc.   \n",
       "2          June 2021                 Goldfinch Bio, Inc.   \n",
       "3      April 4, 2020                 Goldfinch Bio, Inc.   \n",
       "4  December 30, 2020  MolecuLight Inc.|SerenaGroup, Inc.   \n",
       "\n",
       "  Principal Investigator  \n",
       "0                      -  \n",
       "1                      -  \n",
       "2                      -  \n",
       "3                      -  \n",
       "4                      -  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want for a date range(y/n): n\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    d_range=input('Do you want for a date range(y/n): ')\n",
    "    if(d_range=='y'):\n",
    "        date1 = input('From(YYYY-MM-DD): ')\n",
    "        date2 = input('To(YYYY-MM-DD): ')\n",
    "        dates=[]\n",
    "        dates2=[]\n",
    "        start = datetime.datetime.strptime(date1, '%Y-%m-%d')\n",
    "        end = datetime.datetime.strptime(date2, '%Y-%m-%d')\n",
    "        step = datetime.timedelta(days=1)\n",
    "    ################################################################\n",
    "        while start <= end:\n",
    "            dates.append (str(start.date()))\n",
    "            start += step\n",
    "        for i in dates:\n",
    "            a1=i.split('-')\n",
    "            x = datetime.datetime(int(a1[0]),int(a1[1]),int(a1[2]))\n",
    "            dates2.append(x.strftime(\"%B %d, %Y\"))\n",
    "    ##################################################################\n",
    "        appended_data=appended_data.loc[appended_data['Publication Date'].isin(dates)]\n",
    "        a=a.loc[a['Start Date'].isin(dates2)]\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Add not-scraped companies to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patents\n",
    "not_scraped=list(set(l)-set(appended_data['Company Name/Assignee'].unique()))\n",
    "for i in not_scraped:\n",
    "    s2 = pd.DataFrame([i,np.nan,np.nan,np.nan,np.nan,np.nan]).T\n",
    "    s2.columns=appended_data.columns\n",
    "    appended_data=appended_data.append(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials\n",
    "if(all_files!=[]):\n",
    "    not_scraped=list(set(l)-set(a['Company Name'].unique()))\n",
    "    for i in not_scraped:\n",
    "        s2 = pd.DataFrame([i,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan]).T\n",
    "        s2.columns=a.columns\n",
    "        a=a.append(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sheet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patents\n",
    "appended_data2=appended_data.groupby(['Company Name/Assignee']).size().reset_index(name='Value')\n",
    "appended_data2['Patent (Y/N)']=['Y' for i in range(appended_data2.shape[0])]\n",
    "for i in range(appended_data2.shape[0]):\n",
    "    if(appended_data2['Company Name/Assignee'][i] in not_scraped):\n",
    "        appended_data2['Value'][i]=0\n",
    "        appended_data2['Patent (Y/N)'][i]='N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials\n",
    "appended_data3=a.groupby(['Company Name']).size().reset_index(name='Value')\n",
    "appended_data3['Clinical Trials (Y/N)']=['Y' for i in range(appended_data3.shape[0])]\n",
    "for i in range(appended_data3.shape[0]):\n",
    "    if(appended_data3['Company Name'][i] in not_scraped):\n",
    "        appended_data3['Value'][i]=0\n",
    "        appended_data3['Clinical Trials (Y/N)'][i]='N'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Sheet 1 and Sheet 2 as excel\n",
    "name='/BiosectRx Patent Harvest-'+str(today)+'.xlsx'\n",
    "writer = pd.ExcelWriter(directory+name, engine='xlsxwriter')\n",
    "#appended_data.reset_index(inplace=True)\n",
    "#appended_data2.reset_index(inplace=True)\n",
    "appended_data2.to_excel(writer, sheet_name='Patent Check',index=False)\n",
    "appended_data.to_excel(writer, sheet_name='Harvest',index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='/BiosectRx Trials Harvest-'+str(today)+'.xlsx'\n",
    "writer = pd.ExcelWriter(directory+name, engine='xlsxwriter')\n",
    "a.reset_index(inplace=True)\n",
    "appended_data3.reset_index(inplace=True)\n",
    "appended_data3.to_excel(writer, sheet_name='Trials Check',index=False)\n",
    "a.to_excel(writer, sheet_name='Harvest',index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populate in Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge patents and trials\n",
    "df3=pd.merge(appended_data, a, left_on='Company Name/Assignee', right_on='Company Name')\n",
    "df3=df3.drop(['Company Name'],axis=1)\n",
    "df3=df3.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open original template to get format\n",
    "df=pd.read_excel('Template.xlsx')\n",
    "df.columns=df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df3.copy()\n",
    "df5=df5[['Company Name/Assignee', 'Patent No.', 'Title', 'Year Filed',\n",
    "       'Inventors/Authors', 'Clinical Trial Identifier',\n",
    "       'Title of study', 'Start Date', 'End Date', 'Sponsor Company',\n",
    "       'Principal Investigator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df5.columns=['Company Name','Application No','IP Title','IP Year',\n",
    "             'Inventors','Clinical Trial ID','Clinical Title',\n",
    "            'Start Date', 'End Date', 'Sponsor', 'Investigator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=df5.iloc[:,:5]\n",
    "dup_index=set(df6.index)-set(df6.drop_duplicates(keep='first').index)\n",
    "df6.iloc[list(dup_index),1:]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df5.iloc[:,5:]\n",
    "df7['a']=df5['Company Name']\n",
    "dup_index=set(df7.index)-set(df7.drop_duplicates(keep='first').index)\n",
    "df7.iloc[list(dup_index)]=np.NaN\n",
    "df7=df7.drop('a',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=pd.concat([df6,df7],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add null columns as per template\n",
    "for i in set(df.columns)-set(df5.columns):\n",
    "    x[i]=np.nan\n",
    "    \n",
    "# rearrange columns as per template\n",
    "x=x[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=x.groupby('Company Name').count()[['Application No','Clinical Trial ID']]\n",
    "l1,l2=[],[]\n",
    "for i in y['Application No']:\n",
    "    if(i==0):\n",
    "        l1.append('N')\n",
    "    else:\n",
    "        l1.append('Y')\n",
    "for i in y['Clinical Trial ID']:\n",
    "    if(i==0):\n",
    "        l2.append('N')\n",
    "    else:\n",
    "        l2.append('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Patent (Y/N)']=l1\n",
    "y['Clinical Trials (Y/N)']=l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y[['Patent (Y/N)','Application No','Clinical Trials (Y/N)','Clinical Trial ID']]\n",
    "y.columns=['Patent (Y/N)','Value','Clinical Trials (Y/N)','Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.sort_values(by=['Patent (Y/N)', 'Clinical Trials (Y/N)'])\n",
    "ordered_classes = list(y.index)\n",
    "df_list = []\n",
    "for i in ordered_classes:\n",
    "    df_list.append(x[x['Company Name']==i])\n",
    "ordered_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to excel\n",
    "name='/BiosectRx TEMPLATE-'+str(today)+'.xlsx'\n",
    "writer = pd.ExcelWriter(directory+name, engine='xlsxwriter')\n",
    "y.to_excel(writer, sheet_name='Check',index=True)\n",
    "x.to_excel(writer, sheet_name='Harvest',index=False)\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
